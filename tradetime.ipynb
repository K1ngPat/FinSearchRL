{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Nobody likes big warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardModel(nn.Module):\n",
    "    \"\"\"A class we will be using to make neural nets (on every trading day)\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_dim2, output_dim):\n",
    "        super(FeedForwardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, window_size):\n",
    "    \"\"\" A function used to make a set of last window_size days' data as an observation for next day's reward\"\"\"\n",
    "    seq = np.array(seq)\n",
    "    data = []\n",
    "    for i in range(len(seq) - window_size):\n",
    "        window = seq[i:i+window_size].flatten()\n",
    "        target = seq[i+window_size, 3]  # Close of the upcoming day\n",
    "        data.append((window, target))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = './NIFTY_Data'\n",
    "csv_list = os.listdir(data_loc)\n",
    "datasets = []\n",
    "scalers = []\n",
    "window_size = 5   # Number of days data we will be using\n",
    "\n",
    "def ratio(row, ro1, ro2):\n",
    "    if row[ro2] == 0:\n",
    "        return 0\n",
    "    return(row[ro1]/row[ro2])\n",
    "\n",
    "def diff(row, ro1, ro2):\n",
    "    if row[ro2] == 0:\n",
    "        return 0\n",
    "    return(row[ro1]-row[ro2])\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filen in csv_list:\n",
    "    file_address = f'{data_loc}/{filen}'\n",
    "    data = pd.read_csv(file_address)\n",
    "    data['Normalized Close'] = data.apply(lambda row: ratio(row, \"Close\", \"Open\"), axis=1)\n",
    "    data['Ones'] = data.apply(lambda row: ratio(row, \"Close\", \"Close\"), axis=1)\n",
    "    data['Return'] = data.apply(lambda row: diff(row, \"Normalized Close\", \"Ones\"), axis=1)\n",
    "\n",
    "    datasets.append(data[['Open', 'High', 'Low', 'Return', 'Volume']].values)\n",
    "    # Normalize the features between 0 and 1\n",
    "    scalers.append(MinMaxScaler())\n",
    "    datasets[-1] = scalers[-1].fit_transform(datasets[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perstockperday(stockind, currentday, hidden_dim1=256, hidden_dim2=64, epochs=25, lrate=0.003):\n",
    "    \"\"\"Returns predicted_return, actual_return\"\"\"\n",
    "\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = datasets[stockind][:currentday]        # Past data we will use to train\n",
    "    test_data = datasets[stockind][currentday-window_size:currentday+1]     # Contains actual target, which we will return at the same time\n",
    "\n",
    "    # Prepare the training and testing data\n",
    "    train_sequences = prepare_sequence(train_data, window_size)\n",
    "    test_sequences = prepare_sequence(test_data, window_size)\n",
    "\n",
    "    # Convert the sequences to PyTorch tensors\n",
    "    train_inputs = torch.tensor([seq[0] for seq in train_sequences], dtype=torch.float32)\n",
    "    train_targets = torch.tensor([seq[1] for seq in train_sequences], dtype=torch.float32)\n",
    "    test_inputs = torch.tensor([seq[0] for seq in test_sequences], dtype=torch.float32)\n",
    "    test_targets = torch.tensor([seq[1] for seq in test_sequences], dtype=torch.float32)\n",
    "\n",
    "    # Set the hyperparameters\n",
    "    input_dim = window_size*5  # Number of inputs to nn\n",
    "    output_dim = 1  # Number of output features (Close of the upcoming day)\n",
    "\n",
    "\n",
    "    # Initialize the model\n",
    "    model = FeedForwardModel(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lrate)\n",
    "\n",
    "    model.train()\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(train_inputs)\n",
    "        loss = criterion(outputs.view(-1), train_targets.view(-1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss for every few epochs\n",
    "        # if (epoch + 1) % 10 == 0:\n",
    "        #     print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    # output of model\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_inputs)\n",
    "        # test_loss = criterion(test_outputs.view(-1), test_targets.view(-1))\n",
    "        # print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "        # Denormalize the predicted and target prices\n",
    "        dummy_list = torch.Tensor([[0, 0, 0, test_outputs[i], 0] for i in range(len(test_outputs))])\n",
    "        predicted_return = scalers[stockind].inverse_transform(dummy_list.numpy())\n",
    "        dummy_list = torch.Tensor([[0, 0, 0, test_targets[i], 0] for i in range(len(test_targets))])\n",
    "        target_return = scalers[stockind].inverse_transform(dummy_list.numpy())\n",
    "\n",
    "    return predicted_return[0][3], target_return[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perday(currday):\n",
    "    preds = []\n",
    "    rets = []\n",
    "    for i in range(len(datasets)):\n",
    "        predi, reti = perstockperday(i, currday)\n",
    "        preds.append(predi*50)\n",
    "        rets.append(reti+1.00)\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    rets = np.array(rets)\n",
    "    \n",
    "\n",
    "    # THIS WHERE WE DO ALLOCATION OF PORTFOLIO BASED ON PREDICTIONS FOR THE DAY\n",
    "\n",
    "    alloc = softmax(preds)      # For now going with a simple softmax\n",
    "\n",
    "\n",
    "\n",
    "    #return the factor our portfolio changed by\n",
    "    return float(np.sum(alloc * rets, axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trader(endday=2118, startday = 15):\n",
    "    \n",
    "    p = 1.0\n",
    "    facs = []\n",
    "    for dayno in range(startday, endday):\n",
    "        facs.append(perday(dayno))\n",
    "        p *= facs[-1]\n",
    "        print(f\"{p*100}\\t{100*(dayno-startday)/(endday-startday)}%\")\n",
    "    \n",
    "    return facs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a500 = trader(startday=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = trader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
